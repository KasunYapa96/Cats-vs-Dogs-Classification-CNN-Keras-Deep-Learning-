{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-win_amd64.whl (342.5 MB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.13.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.21.3-py2.py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=27910e74095f2c3711ebd1dee1c3e2ef9152e9900bb2ecdca081989da5a78c46\n",
      "  Stored in directory: c:\\users\\kasunyapa\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: keras-preprocessing, absl-py, google-pasta, oauthlib, requests-oauthlib, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-auth-oauthlib, protobuf, markdown, tensorboard-plugin-wit, grpcio, tensorboard, opt-einsum, gast, astunparse, tensorflow-estimator, termcolor, tensorflow\n",
      "Successfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.21.3 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"./dogs-vs-cats/train/train\")\n",
    "\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12324 validated image filenames belonging to 2 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dogs-vs-cats/train/train\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"./dogs-vs-cats/train/tarin\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"./dogs-vs-cats/test/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-f7b6d0c9c94b>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.7533WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 447s 545ms/step - loss: 0.6365 - accuracy: 0.7533\n",
      "Epoch 2/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8118WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 435s 530ms/step - loss: 0.4568 - accuracy: 0.8118\n",
      "Epoch 3/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.8226WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 439s 535ms/step - loss: 0.4320 - accuracy: 0.8226\n",
      "Epoch 4/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8316WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 434s 529ms/step - loss: 0.4102 - accuracy: 0.8316\n",
      "Epoch 5/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8376WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 449s 547ms/step - loss: 0.4012 - accuracy: 0.8376\n",
      "Epoch 6/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.8343WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 467s 568ms/step - loss: 0.3958 - accuracy: 0.8343\n",
      "Epoch 7/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8436WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 467s 569ms/step - loss: 0.3824 - accuracy: 0.8436\n",
      "Epoch 8/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8494WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 500s 609ms/step - loss: 0.3699 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8473WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 431s 525ms/step - loss: 0.3694 - accuracy: 0.8473\n",
      "Epoch 10/10\n",
      "821/821 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8495WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "821/821 [==============================] - 423s 515ms/step - loss: 0.3574 - accuracy: 0.8495\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"./dogs-vs-cats/test1/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kasunyapa\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask utils\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n",
    "# Define a flask app\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model1_catsVSdogs_10epoch.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model='';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-f84ae7cb2fa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mglobal\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mar' is not defined"
     ]
    }
   ],
   "source": [
    "global str\n",
    "\n",
    "str = str(mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-413337bb2291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print('Model loaded. Start serving...')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "model._make_predict_function()         \n",
    "# Necessary\n",
    "# print('Model loaded. Start serving...')\n",
    "\n",
    "# You can also use pretrained model from Keras\n",
    "# Check https://keras.io/applications/\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#model = ResNet50(weights='imagenet')\n",
    "#model.save('')\n",
    "print('Model loaded. Check http://127.0.0.1:5000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
